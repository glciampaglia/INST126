{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b281c94847b72202",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Beyond INST126: Web Scraping\n",
    "\n",
    "In this class activity, we will work on a concrete web scraping task. We will use a special website called [toscrape.com](//toscrape.com) which offers two scraping sandbox environments:\n",
    "1. **[books.toscrape.com](//books.toscrape.com)** &ndash; a fictional bookstore using static pages and pagination,\n",
    "2. **[quotes.toscrape.com](//quotes.toscrape.com)** &ndash; a fictional repository of famous quotes, using API endpoints asynchronous requests.\n",
    "\n",
    "For this activity we will focus **on the book store (books.toscrape.com)** only.\n",
    "\n",
    "## Getting started\n",
    "\n",
    "Visit the bookstore, and browse through a few pages of results. Locate a book price and observe the HTML code associated to it. You will need to know what the HTML looks like in order to extract the price information. To inspect the HTML of page with Firefox or Google Chrome, right-click anywhere on its background (but not on an image), and click `Inspect` or `View Page Source` (the names of these options may be different depending on your browser). \n",
    "\n",
    "Once you have a good idea of what the underlying HTML looks like, start working on the two tasks below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write down your roles\n",
    "DRIVER = \"\"\n",
    "NAVIGATOR = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b281c94847b72202",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Reference -- keep this open while working on the tasks!\n",
    "\n",
    "- [Quickstart guide to Requests](https://requests.readthedocs.io/en/latest/user/quickstart/)\n",
    "- **Cheat sheet of common HTML elements** with examples, split in:\n",
    "  + [Inline elements](https://developer.mozilla.org/en-US/docs/Learn/HTML/Cheatsheet#inline_elements), like links or images;\n",
    "  + [Block elements](https://developer.mozilla.org/en-US/docs/Learn/HTML/Cheatsheet#block_elements), like paragraphs or tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1be21350cbd12b20",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task 1: scrape a single page of results\n",
    "\n",
    "Write a function called `scrapepage` that scrapes all the prices listed on a single page of the bookstore.\n",
    "\n",
    "Your function should take one parameter &ndash; the URL (as a string) of the page to scrape. It should return a list with all the book prices present on the page, converted to float. \n",
    "\n",
    "### Hints\n",
    "\n",
    "1. The text of the response is available in an attribute called `text`. Consider using a `for` loop to iterate through it. As this is a single string (with `\\n` separators), you will need to `.split()` it in multiple lines first.\n",
    "2. To remove the HTML markup sorrounding the price, here too you can make use of the `.split()` method of the string type;\n",
    "3. If you see the symbol `Â` being printed in the price, then make sure to specify the encoding before extracting the price, like this:\n",
    "```\n",
    "    response = requests.get(\"https://books.toscrape.com/\")\n",
    "    response.encoding = 'utf-8'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "# Your solution here\n",
    "...\n",
    "\n",
    "# This will scrape the front page of the bookstore\n",
    "scrapepage(\"https://books.toscrape.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now switch roles\n",
    "DRIVER = \"\"\n",
    "NAVIGATOR = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-7c60cfb18209ef74",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Task 2\n",
    "\n",
    "Write a function called `averageprice` that computes the average price of books found on multiple pages of the bookstore.Your function should call the `scrapepage` function defined above to fetch one page at a time, scrape the book prices, and append them to the final list. Then, it should compute the average price. (For this last step you can convert the list to a Pandas series and make use of the `.mean()` method.)\n",
    "\n",
    "A list with the URLs of ten pages is already provided for you in the cell below. If all goes well, using your function on those URLs should result in an average price of `34.79625`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests \n",
    "import pandas as pd\n",
    "\n",
    "# Your solution here\n",
    "...\n",
    "\n",
    "ten_locations = [\n",
    "    \"https://books.toscrape.com/\",\n",
    "    \"https://books.toscrape.com/catalogue/page-2.html\",\n",
    "    \"https://books.toscrape.com/catalogue/page-3.html\",\n",
    "    \"https://books.toscrape.com/catalogue/page-4.html\",\n",
    "    \"https://books.toscrape.com/catalogue/page-5.html\",\n",
    "    \"https://books.toscrape.com/catalogue/page-6.html\",\n",
    "    \"https://books.toscrape.com/catalogue/page-7.html\",\n",
    "    \"https://books.toscrape.com/catalogue/page-8.html\",\n",
    "    \"https://books.toscrape.com/catalogue/page-9.html\",\n",
    "    \"https://books.toscrape.com/catalogue/page-10.html\"\n",
    "]\n",
    "\n",
    "averageprice(ten_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solutions + Extra Challenge\n",
    "\n",
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "### BEGIN SOLUTION\n",
    "def scrapepage(url):\n",
    "    tmp = []\n",
    "    response = requests.get(url)\n",
    "    response.encoding = \"utf-8\"\n",
    "    for line in response.text.split(\"\\n\"):\n",
    "        if 'price_color' in line:\n",
    "            line = line.strip()\n",
    "            price = line.split(\">\")[1].split(\"<\")[0]\n",
    "            price = price.strip(\"£\")\n",
    "            tmp.append(float(price))\n",
    "    return tmp\n",
    "### END SOLUTION\n",
    "\n",
    "# This will scrape the front page of the bookstore\n",
    "scrapepage(\"https://books.toscrape.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests \n",
    "import pandas as pd\n",
    "\n",
    "## BEGIN SOLUTION\n",
    "def averageprice(locations):\n",
    "    prices = []\n",
    "    for url in locations:\n",
    "        prices.extend(scrapepage(url))\n",
    "    s = pd.Series(prices)\n",
    "    return s.mean()\n",
    "## END SOLUTION\n",
    "\n",
    "ten_locations = [\n",
    "    \"https://books.toscrape.com/\",\n",
    "    \"https://books.toscrape.com/catalogue/page-2.html\",\n",
    "    \"https://books.toscrape.com/catalogue/page-3.html\",\n",
    "    \"https://books.toscrape.com/catalogue/page-4.html\",\n",
    "    \"https://books.toscrape.com/catalogue/page-5.html\",\n",
    "    \"https://books.toscrape.com/catalogue/page-6.html\",\n",
    "    \"https://books.toscrape.com/catalogue/page-7.html\",\n",
    "    \"https://books.toscrape.com/catalogue/page-8.html\",\n",
    "    \"https://books.toscrape.com/catalogue/page-9.html\",\n",
    "    \"https://books.toscrape.com/catalogue/page-10.html\"\n",
    "]\n",
    "\n",
    "averageprice(ten_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Challenge (no solution provided)\n",
    "\n",
    "Modify the `averageprice` function so that, instead of receiving a fixed list of URLs to scrape, identifies the next URL to visit automatically. To do so, you can take advantange of the fact that, at the bottom of each page, there is a &ldquo;Next&rdquo; button pointing to the next page to visit in the sequence."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
